<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="description" content="SpeakEasy: a fully local voice interface for coding with fast dictation, push-to-talk controls, and spoken agent responses designed for low-friction development workflows."><meta name="generator" content="Astro v5.18.0"><title>SpeakEasy: Voice Coding Workflow | Arhum Savera</title><style>:root{--bg: #0f131a;--bg-elev: #151b24;--bg-soft: #1b2430;--line: #293243;--text: #e8edf5;--text-muted: #b2bdcd;--accent: #5fa8ff;--accent-soft: rgba(95, 168, 255, .16);--shadow: 0 12px 34px rgba(3, 8, 18, .45)}*{box-sizing:border-box}html,body{margin:0;padding:0;font-family:Inter,Avenir Next,Segoe UI,sans-serif;background:radial-gradient(1000px 500px at 90% -10%,#1a2436 0%,transparent 60%),radial-gradient(760px 420px at -10% 0%,#17202f 0%,transparent 60%),var(--bg);color:var(--text)}a{color:var(--accent);text-decoration:none}a:hover{text-decoration:underline}.page-shell{min-height:100vh;display:flex;flex-direction:column}.top-nav-wrap{position:sticky;top:0;z-index:30;backdrop-filter:blur(8px)}.top-nav{max-width:1120px;margin:.9rem auto 0;display:flex;align-items:center;justify-content:space-between;gap:1rem;padding:.9rem 1.1rem;border:1px solid var(--line);border-radius:14px;background:#0f141cdb}.brand{color:var(--text);font-size:1.36rem;font-weight:600;letter-spacing:-.01em}.nav-links{display:flex;align-items:center;flex-wrap:wrap;gap:1rem}.nav-links a{color:var(--text-muted);font-size:.96rem}.nav-links a.active,.nav-links a:hover{color:var(--text);text-decoration:none}.main-content{flex:1;max-width:1120px;margin:1.5rem auto 2.4rem;padding:0 1rem;width:100%}.hero{padding:2.3rem;border:1px solid var(--line);border-radius:20px;background:linear-gradient(160deg,#19212ee6,#11161ff0);box-shadow:var(--shadow)}.hero h1{font-size:clamp(2.15rem,5vw,3.7rem);margin:0;letter-spacing:-.03em}.hero p{margin:.95rem 0 0;max-width:48rem;color:var(--text-muted);font-size:clamp(1.02rem,2vw,1.24rem);line-height:1.55}.section{margin-top:1.5rem}.section h2{margin:0 0 .85rem;font-size:clamp(1.4rem,2.4vw,2rem);letter-spacing:-.02em}.panel{border:1px solid var(--line);border-radius:16px;background:linear-gradient(170deg,#19212ddb,#141a24eb);padding:1.15rem 1.2rem;box-shadow:var(--shadow)}.panel p,.panel li{color:var(--text-muted);line-height:1.65}.grid-3{display:grid;grid-template-columns:repeat(3,minmax(0,1fr));gap:.95rem}.grid-2{display:grid;grid-template-columns:repeat(2,minmax(0,1fr));gap:.95rem}.card{border:1px solid var(--line);border-radius:16px;background:linear-gradient(165deg,#171f2be0,#0f141cf2);padding:1rem;transition:transform .14s ease,border-color .14s ease}.card:hover{transform:translateY(-2px);border-color:#3a475d}.card h3{margin:0 0 .48rem;font-size:1.05rem;color:var(--text)}.card p{margin:0;color:var(--text-muted);font-size:.95rem}.badge-row{display:flex;flex-wrap:wrap;gap:.55rem;margin-top:.65rem}.badge{font-size:.8rem;color:#c9d4e3;background:var(--accent-soft);border:1px solid #315178;padding:.25rem .56rem;border-radius:999px}.project-hero{display:grid;gap:1.2rem}.project-hero img{width:100%;max-height:360px;object-fit:cover;border-radius:16px;border:1px solid var(--line)}.project-content h2{margin:1.15rem 0 .5rem;font-size:1.35rem}.project-content p,.project-content li{color:var(--text-muted);line-height:1.68}.list-clean{list-style:none;margin:0;padding:0;display:grid;gap:.85rem}.list-clean li{border:1px solid var(--line);border-radius:14px;padding:.95rem;background:#141b25eb}.site-footer{border-top:1px solid var(--line);margin-top:1rem;padding:1.3rem 1rem 2rem;text-align:center;color:#9eabc0}@media(max-width:940px){.grid-3,.grid-2{grid-template-columns:1fr}.top-nav{border-radius:12px}.brand{font-size:1.18rem}.hero{padding:1.3rem}}
</style></head> <body> <div class="page-shell"> <header class="top-nav-wrap"> <nav class="top-nav"> <a class="brand" href="/">Arhum Savera</a> <div class="nav-links"> <a class href="/about/">About</a> <a class href="/contact/">Contact</a> <a class="active" href="/post/">Projects</a> <a class href="/stack/">Stack</a> <a class href="/lab/">Lab</a> <a href="https://www.linkedin.com/in/arhumsavera/" target="_blank" rel="noopener noreferrer">LinkedIn</a> <a href="https://github.com/arhumsavera" target="_blank" rel="noopener noreferrer">GitHub</a> </div> </nav> </header> <main class="main-content">  <article class="project-hero"> <section class="hero"> <h1>SpeakEasy: Voice Coding Workflow</h1> <p>SpeakEasy: a fully local voice interface for coding with fast dictation, push-to-talk controls, and spoken agent responses designed for low-friction development workflows.</p> <div class="badge-row"> <span class="badge">February 24, 2026</span> </div> </section> <img src="/images/markus-spiske-qjnAnF0jIGk-unsplash.jpg" alt="Hero image for SpeakEasy: Voice Coding Workflow"> <section class="panel project-content">  <h2>System Objective</h2> <p>Voice interaction with coding agents reduces context-switching overhead and keeps hands on keyboard during flow states. Most voice coding tools rely on cloud APIs, introducing latency, privacy concerns, and dependency on external services.</p><p>This project delivers a 100% local voice interface for CLI agents (Claude Code, OpenCode) using warm background servers for near-instant transcription and speech synthesis without ever sending audio or text to the cloud.</p> <h2>Architecture</h2> <ul> <li>Warm HTTP servers: Whisper STT and Kokoro TTS models stay in memory, eliminating cold-start latency (~1.5s first-audio response).</li><li>Push-to-talk workflow: Global Raycast hotkey triggers recording, silence detection ends capture, transcription auto-pastes to active app.</li><li>Agent narration hooks: Claude Code hooks and OpenCode plugins pipe assistant responses through TTS with markdown/code stripping.</li><li>Project-aware voices: Different project directories get distinct voices so you know which agent is speaking.</li><li>Streaming synthesis: Sentences are generated and played incrementally while the next sentence generates in parallel.</li> </ul> <h2>Speech-to-Text Pipeline</h2> <ul> <li>whisper.cpp with Metal acceleration on Apple Silicon (M1-M4) for GPU-native transcription.</li><li>ggml-large-v3-turbo-q5_0 model: strong accuracy with quantized weights (~900MB total).</li><li>HTTP server on port 8787 handles multipart/form-data file uploads and returns JSON with transcribed text.</li><li>Recording uses sox (libsox) for robust cross-device audio capture at 16kHz mono.</li><li>Silence detection with configurable threshold (default 3% over 2 seconds) triggers auto-stop.</li> </ul> <h2>Text-to-Speech Pipeline</h2> <ul> <li>kokoro-onnx: ONNX-based neural TTS with sub-100ms generation times on Apple Silicon.</li><li> voices-v1.0.bin voice pack with 10+ distinct voices (af_heart, am_adam, bf_emma, etc.).</li><li>HTTP server on port 8788 accepts JSON POSTs with text, voice ID, and speed parameters.</li><li>Output streamed as WAV files; afplay (macOS native) handles playback with minimal latency.</li><li>Sentence-level chunking: response text is split on punctuation boundaries, each sentence generated and played in sequence.</li> </ul> <h2>Agent Integrations</h2> <ul> <li>Claude Code: hook scripts in ~/.claude/settings.json capture Stop and Notification events, pipe JSON through sed for markdown stripping, invoke speak command asynchronously.</li><li>OpenCode: TypeScript plugin registers for message.part.updated events, deduplicates consecutive identical messages, spawns detached speak process per response.</li><li>Both integrations run the speak command with --project flag to enable per-directory voice assignment.</li><li>Lock file mechanism (/tmp/speakeasy-speech.lock) prevents TTS from interrupting active dictation.</li> </ul> <h2>CLI and Operator Interface</h2> <ul> <li>Bash CLI with subcommands: setup, server start/stop/status, dictate, speak, mute/unmute, doctor, logs, hook-install.</li><li>Config stored in ~/.config/speakeasy/config with model paths, voice defaults, silence thresholds.</li><li>Doctor command validates dependencies, model files, server health, and hook wiring in one run.</li><li>Logs command aggregates whisper-server, kokoro-server, and plugin output for centralized debugging.</li> </ul> <h2>Performance Characteristics</h2> <ul> <li>STT latency: ~300-500ms for typical command transcription (model warm).</li><li>TTS latency: ~100-150ms per sentence generation, with first sentence playing ~1.5s after response start.</li><li>Memory footprint: Whisper + Kokoro models use ~1.5GB total RAM.</li><li>Zero network dependency: all processing local, works offline after initial model download.</li> </ul> <h2>Reliability and Diagnostics</h2> <ul> <li>Health check endpoints on both servers enable automated restart and status monitoring.</li><li>Graceful degradation: if TTS server unavailable, falls back to kokoro-tts CLI binary.</li><li>Dictation auto-starts servers if not running, ensuring single-command usability.</li><li>Comprehensive doctor checks cover: sox, ffmpeg, jq, whisper-server, uv, Python deps, model files, hook configs.</li> </ul> <h2>Why Local Matters</h2> <p>Cloud STT/TTS APIs introduce network latency, require internet connectivity, and send sensitive code/commands to external services. For developers working on proprietary code or in secure environments, this is a non-starter.</p><p>By keeping everything on-device with warm servers, this system achieves cloud-competitive latency while maintaining complete privacy. The architecture is also more reliable—no API rate limits, no service outages, no vendor lock-in.</p> <p> <a href="https://github.com/arhumsavera" target="_blank" rel="noopener noreferrer">
Code and related repositories
</a> </p> </section> </article>  </main> <footer class="site-footer"> <p>© Arhum Savera 2026</p> </footer> </div> </body></html>